{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a674180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Failed to load transcript.\n",
      "ParseError: no element found: line 1, column 0\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "\n",
    "video_id = \"5MgBikgcWnY\"  # TEDx video\n",
    "docs = []\n",
    "try:\n",
    "    \n",
    "    loader = YoutubeLoader.from_youtube_url(\n",
    "        \"https://www.youtube.com/watch?v=QsYGlZkevEg\", add_video_info=False\n",
    "    )\n",
    "    docs = loader.load()\n",
    "    print(docs)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ Failed to load transcript.\")\n",
    "    print(type(e).__name__ + \":\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49b647f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chat Response:\n",
      " Here's a Python function to reverse a list:\n",
      "\n",
      "```python\n",
      "def reverse_list(lst):\n",
      "    \"\"\"\n",
      "    This function takes a list as input and returns the reversed list.\n",
      "    \"\"\"\n",
      "    return list(reversed(lst))\n",
      "```\n",
      "\n",
      "Explanation:\n",
      "\n",
      "The `reversed()` function returns a reverse iterator for a sequence. We pass our list `lst` to this function and convert the resulting reverse iterator to a list using the `list()` function. This list is then returned by the function.\n",
      "\n",
      "Example usage:\n",
      "\n",
      "```python\n",
      "my_list = [1, 2, 3, 4, 5]\n",
      "reversed_list = reverse_list(my_list)\n",
      "print(reversed_list)  # Output: [5, 4, 3, 2, 1]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# Paste your HF token here or set via environment variable\n",
    "token = os.getenv('HF_TOKEN')\n",
    "\n",
    "# Pick a chat-supported model\n",
    "model_id = \"HuggingFaceH4/zephyr-7b-beta\"  # Example\n",
    "\n",
    "client = InferenceClient(model=model_id, token=token)\n",
    "\n",
    "# OpenAI-style chat message format\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful coding assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write a Python function to reverse a list.\"}\n",
    "]\n",
    "\n",
    "# Call chat_completion\n",
    "response = client.chat_completion(\n",
    "    messages=messages,\n",
    "    max_tokens=200,\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "print(\"✅ Chat Response:\\n\", response.choices[0].message[\"content\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
