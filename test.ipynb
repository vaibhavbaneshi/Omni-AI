{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a674180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "\n",
    "video_id = \"5MgBikgcWnY\"  # TEDx video\n",
    "docs = []\n",
    "try:\n",
    "    \n",
    "    loader = YoutubeLoader.from_youtube_url(\n",
    "        \"https://www.youtube.com/watch?v=QsYGlZkevEg\", add_video_info=False\n",
    "    )\n",
    "    docs = loader.load()\n",
    "    print(docs)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ Failed to load transcript.\")\n",
    "    print(type(e).__name__ + \":\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b647f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# Paste your HF token here or set via environment variable\n",
    "token = os.getenv('HF_TOKEN')\n",
    "\n",
    "# Pick a chat-supported model\n",
    "model_id = \"HuggingFaceH4/zephyr-7b-beta\"  # Example\n",
    "\n",
    "client = InferenceClient(model=model_id, token=token)\n",
    "\n",
    "# OpenAI-style chat message format\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful coding assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write a Python function to reverse a list.\"}\n",
    "]\n",
    "\n",
    "# Call chat_completion\n",
    "response = client.chat_completion(\n",
    "    messages=messages,\n",
    "    max_tokens=200,\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "print(\"✅ Chat Response:\\n\", response.choices[0].message[\"content\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79a145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────────────────────────────────────────\n",
    "# 1. Imports and Environment Setup\n",
    "# ───────────────────────────────────────────────\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from crewai import Agent, Task, Crew, Process, LLM\n",
    "from crewai_tools import YoutubeChannelSearchTool\n",
    "\n",
    "# Prevent any OpenAI fallback errors\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"DUMMY\"  # Safety fallback\n",
    "\n",
    "# ───────────────────────────────────────────────\n",
    "# 2. Configure Groq LLM\n",
    "# ───────────────────────────────────────────────\n",
    "llm = LLM(\n",
    "    model=\"llama3-8b-8192\",  # Fast and supported\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\")\n",
    ")\n",
    "\n",
    "# ───────────────────────────────────────────────\n",
    "# 3. Set up YouTube Tool (force using Groq LLM)\n",
    "# ───────────────────────────────────────────────\n",
    "yt_tool = YoutubeChannelSearchTool(\n",
    "    youtube_channel_handle=\"@IBMTechnology\",\n",
    "    llm=llm  # 👈 inject your Groq LLM to avoid OpenAI fallback\n",
    ")\n",
    "\n",
    "# ───────────────────────────────────────────────\n",
    "# 4. Define Agents\n",
    "# ───────────────────────────────────────────────\n",
    "researcher = Agent(\n",
    "    role=\"Video Summarizer\",\n",
    "    goal=\"Summarize insights from a YouTube video\",\n",
    "    backstory=\"Expert at analyzing YouTube educational content and summarizing key takeaways.\",\n",
    "    tools=[yt_tool],\n",
    "    verbose=True,\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "writer = Agent(\n",
    "    role=\"Blog Writer\",\n",
    "    goal=\"Write a blog post from a video summary\",\n",
    "    backstory=\"An AI blogger who transforms summaries into engaging articles.\",\n",
    "    verbose=True,\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "# ───────────────────────────────────────────────\n",
    "# 5. Define Tasks\n",
    "# ───────────────────────────────────────────────\n",
    "research_task = Task(\n",
    "    description=(\n",
    "        \"Use the YouTube tool to find a video about '{topic}'. \"\n",
    "        \"Extract and summarize the video content.\"\n",
    "    ),\n",
    "    expected_output=\"A clear, concise summary of the selected video.\",\n",
    "    tools=[yt_tool],\n",
    "    agent=researcher\n",
    ")\n",
    "\n",
    "write_task = Task(\n",
    "    description=(\n",
    "        \"Write a 500-word blog post from the summary. Use a clear, journalistic tone with strong structure \"\n",
    "        \"and simple explanations, aimed at general readers interested in defense and geopolitics.\"\n",
    "    ),\n",
    "    expected_output=\"A titled blog post with intro, body, and conclusion.\",\n",
    "    agent=writer\n",
    ")\n",
    "\n",
    "# ───────────────────────────────────────────────0\n",
    "# 6. Create and Run Crew\n",
    "# ───────────────────────────────────────────────\n",
    "crew = Crew(\n",
    "    agents=[researcher, writer],\n",
    "    tasks=[research_task, write_task],\n",
    "    process=Process.sequential,\n",
    "    memory=False,\n",
    "    cache=False,\n",
    "    embedder={\"provider\": \"none\"},\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "result = crew.kickoff(inputs={\"topic\": \"What is LangChain?\"})\n",
    "print(\"\\n📄 Final Blog Output:\\n\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e669fb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yt-dlp youtube-transcript-api crewai crewai_tools langchain_groq python-dotenv tiktoken requests tqdm pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e215833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────────────────────────────────────────\n",
    "# 0. Setup – environment keys & imports\n",
    "# ───────────────────────────────────────────────\n",
    "import os, time, subprocess, tempfile\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "from dotenv import load_dotenv\n",
    "from crewai import Agent, Task, Crew, Process, LLM\n",
    "import requests\n",
    "import re\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ───────────────────────────────────────────────\n",
    "# 1. Helpers: video ID & shell\n",
    "# ───────────────────────────────────────────────\n",
    "def extract_video_id(url):\n",
    "    q = parse_qs(urlparse(url).query)\n",
    "    return q.get(\"v\", [\"\"])[0]\n",
    "\n",
    "def run_cmd(cmd):\n",
    "    proc = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    if proc.returncode != 0:\n",
    "        raise RuntimeError(proc.stderr.strip() or \"Command failed\")\n",
    "    return proc.stdout.strip()\n",
    "\n",
    "# ───────────────────────────────────────────────\n",
    "# 2. Download captions or fallback to audio\n",
    "# ───────────────────────────────────────────────\n",
    "def fetch_captions_or_audio(video_url, work_dir):\n",
    "    vid_id = extract_video_id(video_url)\n",
    "\n",
    "    # Try downloading captions\n",
    "    try:\n",
    "        print(\"🔎 Checking for captions …\")\n",
    "        sub_cmd = [\n",
    "            \"yt-dlp\", \"--skip-download\",\n",
    "            \"--write-auto-sub\", \"--sub-lang\", \"en\",\n",
    "            \"-o\", f\"{work_dir}/%(id)s.%(ext)s\",\n",
    "            video_url\n",
    "        ]\n",
    "        run_cmd(sub_cmd)\n",
    "        vtt = next(work_dir.glob(f\"{vid_id}.en.vtt\"))\n",
    "        print(\"✅ Captions downloaded.\")\n",
    "        return vtt\n",
    "    except:\n",
    "        print(\"⚠️ No captions found, downloading audio …\")\n",
    "\n",
    "    # Download audio\n",
    "    audio_cmd = [\n",
    "        \"yt-dlp\", \"-f\", \"bestaudio\",\n",
    "        \"--extract-audio\", \"--audio-format\", \"mp3\",\n",
    "        \"-o\", f\"{work_dir}/%(id)s.%(ext)s\",\n",
    "        video_url\n",
    "    ]\n",
    "    run_cmd(audio_cmd)\n",
    "    mp3 = next(work_dir.glob(f\"{vid_id}.mp3\"))\n",
    "    print(\"✅ Audio downloaded.\")\n",
    "    return mp3\n",
    "\n",
    "# ───────────────────────────────────────────────\n",
    "# 3. Transcript Tools\n",
    "# ───────────────────────────────────────────────\n",
    "def clean_vtt_transcript(vtt_path):\n",
    "    with vtt_path.open(\"r\", encoding=\"utf8\") as f:\n",
    "        raw_text = f.read()\n",
    "    \n",
    "    print(\"\\n📄 RAW VTT FILE CONTENT (First 500 chars):\\n\")\n",
    "    print(raw_text[:500])  # Don't skip this!\n",
    "\n",
    "    if not raw_text.strip():\n",
    "        raise ValueError(\"🛑 VTT file is completely empty. No captions were downloaded.\")\n",
    "\n",
    "    # Continue cleaning...\n",
    "\n",
    "\n",
    "def extract_transcript(vtt_text):\n",
    "    # Remove timestamps like \"00:00:00.160 --> 00:00:01.990\"\n",
    "    text = re.sub(r\"\\d{2}:\\d{2}:\\d{2}\\.\\d{3} --> \\d{2}:\\d{2}:\\d{2}\\.\\d{3}\", \"\", vtt_text)\n",
    "    # Remove captions metadata (e.g., \"align:start position:0%\")\n",
    "    text = re.sub(r\"align:start position:\\d+%\", \"\", text)\n",
    "    # Remove lines like \"Kind: captions Language: en\"\n",
    "    text = re.sub(r\"Kind:.*Language:.*\", \"\", text)\n",
    "    # Remove all excess whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    print('extract_transcript \\n' + text)\n",
    "    return text.strip()\n",
    "\n",
    "def assemblyai_transcribe(audio_path):\n",
    "    ASSEMBLYAI_KEY = os.getenv(\"ASSEMBLY_API_KEY\")\n",
    "    headers = {\"authorization\": ASSEMBLYAI_KEY}\n",
    "\n",
    "    print(\"⬆️ Uploading to AssemblyAI …\")\n",
    "    with audio_path.open(\"rb\") as f:\n",
    "        res = requests.post(\"https://api.assemblyai.com/v2/upload\", headers=headers, data=f)\n",
    "        upload_url = res.json()[\"upload_url\"]\n",
    "\n",
    "    res = requests.post(\n",
    "        \"https://api.assemblyai.com/v2/transcript\",\n",
    "        headers=headers, json={\"audio_url\": upload_url}\n",
    "    )\n",
    "    transcript_id = res.json()[\"id\"]\n",
    "\n",
    "    print(\"⏳ Transcribing …\")\n",
    "    while True:\n",
    "        poll = requests.get(f\"https://api.assemblyai.com/v2/transcript/{transcript_id}\", headers=headers).json()\n",
    "        if poll[\"status\"] == \"completed\":\n",
    "            return poll[\"text\"]\n",
    "        elif poll[\"status\"] == \"error\":\n",
    "            raise RuntimeError(poll[\"error\"])\n",
    "        time.sleep(5)\n",
    "\n",
    "# ───────────────────────────────────────────────\n",
    "# 4. Groq LLM Setup\n",
    "# ───────────────────────────────────────────────\n",
    "groq_llm = LLM(\n",
    "    model=\"llama3-8b-8192\",\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\")\n",
    ")\n",
    "\n",
    "# ───────────────────────────────────────────────\n",
    "# 5. Main Pipeline\n",
    "# ───────────────────────────────────────────────\n",
    "def youtube_blog_pipeline(video_url):\n",
    "    with tempfile.TemporaryDirectory() as tmp:\n",
    "        tmp_path = Path(tmp)\n",
    "        file_path = fetch_captions_or_audio(video_url, tmp_path)\n",
    "\n",
    "        if file_path.suffix == \".vtt\":\n",
    "            transcript = clean_vtt_transcript(file_path)\n",
    "            transcript_text = extract_transcript(transcript)\n",
    "            print(\"Transcript Text \\n\" + transcript_text)\n",
    "        else:\n",
    "            transcript_text = assemblyai_transcribe(file_path)\n",
    "\n",
    "        # ✅ Limit input to 14,000 characters\n",
    "        if len(transcript_text) > 14000:\n",
    "            print(f\"⚠️ Transcript truncated to 14,000 chars from {len(transcript_text)}\")\n",
    "            transcript_text = transcript_text[:14000]\n",
    "\n",
    "        # ── Agents\n",
    "        summarizer = Agent(\n",
    "            role=\"Video Summarizer\",\n",
    "            goal=\"Summarize the transcript clearly and concisely.\",\n",
    "            backstory=\"Expert in extracting concise information from long-form content.\",\n",
    "            verbose=True,\n",
    "            llm=groq_llm\n",
    "        )\n",
    "\n",
    "        blogger = Agent(\n",
    "            role=\"Blog Writer\",\n",
    "            goal=\"Create a compelling blog post from the summary.\",\n",
    "            backstory=\"Skilled blogger who turns complex info into readable articles.\",\n",
    "            verbose=True,\n",
    "            llm=groq_llm\n",
    "        )\n",
    "\n",
    "        # ── Tasks\n",
    "        summary_task = Task(\n",
    "            description=f\"\"\"You are a professional video summarizer. Summarize the following transcript into 10–12 clear bullet points, covering all key topics and insights from the video. Do **not** include any explanation or meta-commentary, just return the bullet points as your final output.\n",
    "\n",
    "        Transcript:\n",
    "        {transcript_text}\n",
    "        \"\"\",\n",
    "            expected_output=\"10–12 bullet points summarizing the video.\",\n",
    "            agent=summarizer\n",
    "        )\n",
    "\n",
    "\n",
    "        # ── Summarize First\n",
    "        crew_summary = Crew(\n",
    "            agents=[summarizer],\n",
    "            tasks=[summary_task],\n",
    "            process=Process.sequential,\n",
    "            memory=False,\n",
    "            cache=False,\n",
    "            embedder={\"provider\": \"none\"},\n",
    "            llm=groq_llm,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        summary_output = crew_summary.kickoff()\n",
    "\n",
    "        print(\"\\n📌 Video Summary:\\n\", summary_output.tasks_output)\n",
    "\n",
    "        # ── Write Blog Based on Summary\n",
    "        blog_task = Task(\n",
    "            description=f\"\"\"Write a 500-word blog post based on this summary:\n",
    "            \n",
    "            {summary_output}\n",
    "            \n",
    "        Use a catchy title, intro, subheadings, and conclusion. Format the output in Markdown.\"\"\",\n",
    "            expected_output=\"Markdown-formatted blog article.\",\n",
    "            agent=blogger\n",
    "        )\n",
    "\n",
    "        crew_blog = Crew(\n",
    "            agents=[blogger],\n",
    "            tasks=[blog_task],\n",
    "            process=Process.sequential,\n",
    "            memory=False,\n",
    "            cache=False,\n",
    "            embedder={\"provider\": \"none\"},\n",
    "            llm=groq_llm,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        blog_result = crew_blog.kickoff()\n",
    "        return blog_result\n",
    "\n",
    "# ───────────────────────────────────────────────\n",
    "# 6. Run\n",
    "# ───────────────────────────────────────────────\n",
    "video = \"https://www.youtube.com/watch?v=rUCOwCJDh8o&ab_channel=Fireship\"\n",
    "blog_output = youtube_blog_pipeline(video)\n",
    "\n",
    "print(\"\\n📝 Final Blog Output:\\n\")\n",
    "print(blog_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
